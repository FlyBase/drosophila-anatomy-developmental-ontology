{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "makes robot template to generate provisional cell types \n",
    "based on type:ID mapping in 'new_cell_types.tsv' (does not use 'FBbt_name' in file)\n",
    "may need to copy across latest hemibrain ROI mapping if this gets updated\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import neuprint\n",
    "\n",
    "# for connecting to neuPrint (add token)\n",
    "token = \"\"\n",
    "np_client = neuprint.Client('https://neuprint.janelia.org', dataset='hemibrain:v1.2.1', token=token)\n",
    "\n",
    "# load file with types mapped to FBbt:2... IDs, labels, refs\n",
    "cell_types = pd.read_csv('./new_cell_types.tsv', sep='\\t', dtype='str', na_filter=False)\n",
    "\n",
    "# copy across latest ROI mapping file from hemibrain_metadata and load\n",
    "full_roi_mapping = pd.read_csv('./hemibrain_1-1_ROI_mapping.tsv', sep='\\t')\n",
    "\n",
    "# minimum no. synapses to add region connectivity\n",
    "connectivity_threshold = 10\n",
    "#len(cell_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter cell_types to remove any that are in FlyWire annotations file\n",
    "# (these will be updated using ../flywire_neurons/flywire_neurons.ipynb)\n",
    "# annotations file at https://github.com/flyconnectome/flywire_annotations/tree/main/supplemental_files\n",
    "flywire_annotations = pd.read_csv(\"../flywire_neurons/Supplemental_file1_neuron_annotations.tsv\", \n",
    "                                  sep=\"\\t\", dtype=\"str\")\n",
    "\n",
    "cell_types = cell_types[~(cell_types['np_type'].isin(flywire_annotations['cell_type'])\\\n",
    "    |cell_types['np_type'].isin(flywire_annotations['hemibrain_type']))].reset_index()\n",
    "#len(cell_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add entry for 'posterior slope' and 'clamp' (not in hemibrain ROIs?)\n",
    "extra_regions = pd.DataFrame({'ROI': ['PS(R)', 'PS(L)','CL(R)','CL(L)'], \n",
    "                              'FBbt_id': ['FBbt:00040072','FBbt:00040072','FBbt:00040047','FBbt:00040047'],\n",
    "                              'FBbt_name': ['posterior slope','posterior slope','clamp','clamp']})\n",
    "\n",
    "full_roi_mapping = pd.concat([full_roi_mapping, extra_regions], \n",
    "                   ignore_index=True)\n",
    "\n",
    "# fix 'NO' and any other leading and trailing '\n",
    "full_roi_mapping['ROI'] = full_roi_mapping['ROI'].apply(lambda x: x.strip(\"'\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of raw ROI names to FBbt\n",
    "raw_ROI_dict = dict(zip(full_roi_mapping['ROI'],full_roi_mapping['FBbt_id']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove left/right, keep only capitalised regions\n",
    "tidy_roi_mapping = full_roi_mapping\n",
    "tidy_roi_mapping['ROI'] = tidy_roi_mapping['ROI'].map(\n",
    "    lambda x: re.compile('\\([LR]+\\)').sub('',x))\n",
    "tidy_roi_mapping = tidy_roi_mapping[tidy_roi_mapping['ROI'].str.match('[A-Z]+$')==True]\n",
    "tidy_roi_mapping = tidy_roi_mapping.drop_duplicates().reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patterns for different types of neuprint label (used by functions)\n",
    "TI_pattern = re.compile(\"([A-Z]+)([0-9][0-9][0-9]$)\")\n",
    "multiPN_pattern = re.compile(\"(M_)([lvad]+[2]?)(PN)([0-9]*[mlt]+)([0-9]+[A-Z]?)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe of neuroblasts\n",
    "\n",
    "nb_data = np.array([['FBbt:00067348', 'v', 'ALv1'], ['FBbt:00050035', 'v2', 'ALv2'], \\\n",
    "                    ['FBbt:00050038', 'lv', 'ALlv1'], ['FBbt:00067346', 'ad', 'ALad1'], \\\n",
    "                    ['FBbt:00067347', 'l', 'ALl1 (Notch OFF hemilineage)'], \\\n",
    "                    ['FBbt:00067347', 'l2', 'ALl1 (Notch ON hemilineage)']])\n",
    "neuroblasts = pd.DataFrame(nb_data, columns=['ID', 'short', 'name'])\n",
    "neuroblasts = neuroblasts.set_index('short')\n",
    "#neuroblasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe of tracts\n",
    "\n",
    "tract_data = np.array([['FBbt:00003985', 'm', 'medial antennal lobe tract'], \\\n",
    "                       ['FBbt:00003983', 'l', 'lateral antennal lobe tract'], \\\n",
    "                       ['FBbt:00003984', 'ml', 'mediolateral antennal lobe tract'], \\\n",
    "                       ['FBbt:00049719', '10t', 'transverse antennal lobe t10ALT tract']])\n",
    "tracts = pd.DataFrame(tract_data, columns=['ID', 'short', 'name'])\n",
    "tracts = tracts.set_index('short')\n",
    "#tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all individuals of each type and their region connectivity\n",
    "query = (\"MATCH (n:Neuron) WHERE n.type IN %s \"\n",
    "         \"RETURN n.type, n.bodyId, apoc.convert.fromJsonMap(n.roiInfo) AS ROIs\" \n",
    "         % cell_types.np_type.tolist())\n",
    "\n",
    "np_results = np_client.fetch_custom(query)\n",
    "np_results = np_results.set_index(['n.type','n.bodyId'])\n",
    "#print(np_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split each region into a column, map column names to FBbt, then stack ROI columns into index\n",
    "connecivity_by_ROI = np_results.ROIs.apply(pd.Series)\n",
    "connecivity_by_ROI = connecivity_by_ROI.stack(future_stack=True)\n",
    "#print(connecivity_by_ROI.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split out connectivity type (pre, post etc) into columns (SLOW)\n",
    "connectivity_table_1 = connecivity_by_ROI.apply(pd.Series)\n",
    "connectivity_table_1.index = connectivity_table_1.index.rename(['type', 'bodyID','ROI_np'])\n",
    "#print(connectivity_table_1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map neuprint ROIs to FBbt and tidy up\n",
    "connectivity_table = connectivity_table_1.reset_index(level='ROI_np', drop=False)\n",
    "connectivity_table['ROI'] = connectivity_table['ROI_np'].map(raw_ROI_dict)\n",
    "connectivity_table = connectivity_table.drop(labels = ['downstream', 'upstream', 0, 'ROI_np'], axis=1)\n",
    "connectivity_table = connectivity_table.set_index('ROI', append=True)\n",
    "connectivity_table = connectivity_table.fillna(0)\n",
    "#print(connectivity_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get max connectivity per region per bodyID (groups duplicate regions)\n",
    "body_connectivity_table = connectivity_table.groupby(['type', 'bodyID','ROI']).agg({'post':'max', 'pre':'max'})\n",
    "\n",
    "# get min connectivity per region per type (groups multiple bodies per type)\n",
    "type_connectivity_table = body_connectivity_table.groupby(['type', 'ROI']).agg({'post':'min', 'pre':'min'})\n",
    "\n",
    "# drop rows where pre and post are both 0\n",
    "type_connectivity_table = type_connectivity_table.drop(type_connectivity_table[type_connectivity_table['post'].eq(0) & type_connectivity_table['pre'].eq(0)].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_checker(shortname):\n",
    "    if re.match(TI_pattern,shortname):\n",
    "        return 'TI'\n",
    "    elif re.match(multiPN_pattern,shortname):\n",
    "        return 'multi'\n",
    "    else:\n",
    "        raise ValueError(\"Invalid neuron name - \" + shortname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_lister(names):\n",
    "    L = \"\"\n",
    "    if len(names) < 1:\n",
    "        return False\n",
    "    elif len(names) == 1:\n",
    "        return names[0]\n",
    "    elif len(names) > 1:\n",
    "        L = names[0]\n",
    "        if len(names) > 2:\n",
    "            for i in names[1:-1]:\n",
    "                L = L + \", \" + i\n",
    "        L = L + \" and \" + names[-1]\n",
    "        return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuropil_writer(roi):\n",
    "    \"\"\"returns neuropil name for a short roi name or an FBbt_ID\"\"\"\n",
    "    if re.match('FBbt',roi):\n",
    "        neuropil = str(list(full_roi_mapping[full_roi_mapping['FBbt_id'] == roi]['FBbt_name'])[0])\n",
    "    elif roi in list(tidy_roi_mapping['ROI']):\n",
    "        neuropil = str(list(tidy_roi_mapping[tidy_roi_mapping['ROI'] == roi]['FBbt_name'])[0])\n",
    "    elif roi in list(full_roi_mapping['ROI']):\n",
    "        neuropil = str(list(full_roi_mapping[full_roi_mapping['ROI'] == roi]['FBbt_name'])[0])\n",
    "    else:\n",
    "        raise KeyError(\"Input to neuropil_wirter must be a valid roi or FBbt ID!\")\n",
    "    \n",
    "    return neuropil.replace('adult ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for terra incognita neurons\n",
    "\n",
    "def shortname_splitter(shortname):\n",
    "    \"\"\"\n",
    "    Splits neuron names - at least one (uppercase) letter / three digits.\n",
    "    \"\"\"\n",
    "    name_type = type_checker(shortname)\n",
    "    if name_type == 'TI':\n",
    "        m = re.match(TI_pattern, shortname)\n",
    "    elif name_type == 'multi':\n",
    "        m = re.match(multiPN_pattern, shortname)\n",
    "        \n",
    "    if m: return m.groups()\n",
    "    else:\n",
    "        raise ValueError(shortname + \"could not be split.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_maker(shortname):\n",
    "    \"\"\"\n",
    "    Autogenerates term label based on neuprint type name.\n",
    "    \"\"\"\n",
    "    if type_checker(shortname) == 'TI':\n",
    "        neuropil = neuropil_writer(shortname_splitter(shortname)[0])\n",
    "        return \"adult %s neuron %s\" % (neuropil, shortname_splitter(shortname)[1])\n",
    "    elif type_checker(shortname) == 'multi':\n",
    "        return \"adult multiglomerular antennal lobe projection neuron type %s %sPN\" % \\\n",
    "            (shortname_splitter(shortname)[4], shortname_splitter(shortname)[1])\n",
    "    else:\n",
    "        raise ValueError(\"Could not make label for \" + shortname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def definition_maker(shortname):\n",
    "    \"\"\"\n",
    "    Autogenerates term definition based on neuprint type name.\n",
    "    \"\"\"\n",
    "    definition = \"\"\n",
    "    if type_checker(shortname) == 'TI':\n",
    "        definition += (\"Adult neuron belonging to group %s of the terra incognita neurons \"\n",
    "                       \"with substantial synapsing in the %s (Scheffer et al., 2020).\" \n",
    "                       % (shortname_splitter(shortname)[1], neuropil_writer(shortname_splitter(shortname)[0])))\n",
    "    elif type_checker(shortname) == 'multi':\n",
    "        definition += (\"Adult multiglomerular antennal lobe projection neuron belonging to group %s \"\n",
    "                   \"(Scheffer et al., 2020). It develops from neuroblast %s and follows \"\n",
    "                   \"the %s (Bates et al., 2020; Scheffer et al., 2020).\" \n",
    "                   % (shortname_splitter(shortname)[4], neuroblasts['name'][shortname_splitter(shortname)[1]], \n",
    "                   tracts['name'][shortname_splitter(shortname)[3]]))\n",
    "    else:\n",
    "        raise ValueError(\"Could not make definition for \" + shortname)\n",
    "        \n",
    "    # connectivity\n",
    "    try:\n",
    "        type_connectivity = type_connectivity_table.loc[shortname]\n",
    "        \n",
    "        postsynapses = []\n",
    "        postsynapse_names = []\n",
    "        for region in type_connectivity.index:\n",
    "            if type_connectivity['post'][region] >= connectivity_threshold:\n",
    "                postsynapses.append(region)\n",
    "        if postsynapses:\n",
    "            for i in postsynapses:\n",
    "                label = neuropil_writer(i)\n",
    "                postsynapse_names.append(label)\n",
    "            definition += (\" It has postsynaptic sites in the %s (Scheffer et al., 2020).\" \n",
    "                           % name_lister(postsynapse_names))\n",
    "        \n",
    "        presynapses = []\n",
    "        presynapse_names = []\n",
    "        for region in type_connectivity.index:\n",
    "            if type_connectivity['pre'][region] >= connectivity_threshold:\n",
    "                presynapses.append(region)\n",
    "        if presynapses:\n",
    "            for i in presynapses:\n",
    "                label = neuropil_writer(i)\n",
    "                presynapse_names.append(label)\n",
    "            definition += (\" It has presynaptic sites in the %s (Scheffer et al., 2020).\" \n",
    "                           % name_lister(presynapse_names))\n",
    "        \n",
    "    except(KeyError):\n",
    "        pass\n",
    "    \n",
    "    return definition\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary with key - column header & value = template specification (first row of table).\n",
    "\n",
    "template_seed = OrderedDict([ ('ID' , 'ID'), ('CLASS_TYPE' , 'CLASS_TYPE'),\\\n",
    "                             ('TYPE' , 'TYPE' )])\n",
    "\n",
    "# fields for obo ID and namespace\n",
    "template_seed.update([(\"obo_id\" , \"A oboInOwl:id\"), (\"obo_namespace\" , \"A oboInOwl:hasOBONamespace\")])\n",
    "\n",
    "#label, definition, creation:\n",
    "template_seed.update([(\"label\" , \"A rdfs:label\"), (\"definition\" , \"A IAO:0000115\"),\\\n",
    "                      (\"Xref_def\" , \">A oboInOwl:hasDbXref SPLIT=|\"),\\\n",
    "                      (\"created_by\" , \"AI dc:contributor\"),\\\n",
    "                      (\"creation_date\", \"AT dc:date^^xsd:dateTime\")])\n",
    "\n",
    "#synonyms, comment:\n",
    "template_seed.update([(\"synonym\" , \"A oboInOwl:hasExactSynonym\"),\\\n",
    "                      (\"syn_ref\" , \">A oboInOwl:hasDbXref\"),\\\n",
    "                      (\"additional_synonym\", \"A oboInOwl:hasRelatedSynonym\"),\\\n",
    "                      (\"additional_synonym_ref\", \">A oboInOwl:hasDbXref\"),\\\n",
    "                      (\"comment\" , \"A rdfs:comment\")])\n",
    "\n",
    "# Columns for relationships:\n",
    "template_seed.update([(\"synapses\", \"SC 'has synaptic IO in region' some %\"),\\\n",
    "                      (\"inputs\", \"SC 'receives synaptic input in region' some %\"),\\\n",
    "                      (\"parent\", \"SC % SPLIT=|\"), (\"neuroblast\", \"SC 'develops from' some %\"),\\\n",
    "                      (\"tract\", \"SC 'fasciculates with' some %\"), (\"hemilineage\", \"SC %\"),\\\n",
    "                      (\"inputs\", \"SC 'receives synaptic input in region' some % SPLIT=|\"),\\\n",
    "                      (\"outputs\", \"SC 'sends synaptic output to region' some % SPLIT=|\")])\n",
    "\n",
    "# Create dataFrame for template\n",
    "template = pd.DataFrame.from_records([template_seed])\n",
    "\n",
    "#template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0 # first row\n",
    "id_mapping = {} # dictionary of ids for types\n",
    "\n",
    "for i in cell_types.index:\n",
    "\n",
    "    row_od = OrderedDict([]) #new template row as an empty ordered dictionary\n",
    "    for c in template.columns: #make columns and blank data for new template row\n",
    "        row_od.update([(c , \"\")])\n",
    "    \n",
    "    np_type = cell_types['np_type'][i]\n",
    "    \n",
    "    Parents_list = []\n",
    "    if cell_types.asserted_parents[i]:\n",
    "        Parents_list.extend(cell_types.asserted_parents[i].split('|'))\n",
    "    \n",
    "    #these are the same in each row\n",
    "    row_od[\"CLASS_TYPE\"] = \"subclass\"\n",
    "    row_od[\"TYPE\"] = \"owl:Class\"\n",
    "    row_od[\"created_by\"] = \"http://orcid.org/0000-0002-1373-1705\"\n",
    "    row_od[\"creation_date\"] = cell_types['date'][i]\n",
    "    row_od[\"comment\"] = str(\"Uncharacterized putative cell type (based on clustering analysis) \"\n",
    "        \"from Janelia hemibrain data (Scheffer et al., 2020).\")\n",
    "    row_od['obo_namespace'] = \"fly_anatomy.ontology\"\n",
    "\n",
    "    #easy to generate data\n",
    "    row_od[\"ID\"] = cell_types['FBbt_id'][i]\n",
    "    row_od['obo_id'] = cell_types['FBbt_id'][i]\n",
    "    row_od[\"synonym\"] = \"adult %s neuron\" % np_type\n",
    "    row_od[\"syn_ref\"] = cell_types['ref'][i]\n",
    "    row_od[\"additional_synonym\"] = cell_types['synonym'][i]\n",
    "    row_od[\"additional_synonym_ref\"] = cell_types['synonym_ref'][i]\n",
    "    row_od[\"label\"] = label_maker(np_type)\n",
    "    row_od[\"definition\"] = definition_maker(np_type)\n",
    "    row_od[\"Xref_def\"] = cell_types['ref'][i]\n",
    "    \n",
    "    # conditional\n",
    "    if type_checker(np_type) == 'TI':\n",
    "        Parents_list.append(\"FBbt:00047095\") # adult neuron\n",
    "        row_od[\"synapses\"] = str(list(tidy_roi_mapping[tidy_roi_mapping['ROI'] == shortname_splitter(np_type)[0]]['FBbt_id'])[0])\n",
    "        \n",
    "    if type_checker(np_type) == 'multi':\n",
    "        Parents_list.append(\"FBbt:00007441\") # adult multiglomerular antennal lobe projection neuron\n",
    "        row_od[\"neuroblast\"] = neuroblasts['ID'][shortname_splitter(np_type)[1]]\n",
    "        row_od[\"tract\"] = tracts['ID'][shortname_splitter(np_type)[3]]\n",
    "        row_od[\"inputs\"] = str(list(tidy_roi_mapping[tidy_roi_mapping['ROI'] == 'AL']['FBbt_id'])[0])\n",
    "        row_od[\"Xref_def\"]+=(\"|FlyBase:FBrf0246460\")\n",
    "        \n",
    "    if 'Notch OFF' in row_od[\"definition\"]:\n",
    "        row_od[\"hemilineage\"] = 'FBbt:00049540'\n",
    "    elif 'Notch ON' in row_od[\"definition\"]:\n",
    "        row_od[\"hemilineage\"] = 'FBbt:00049539'\n",
    "    \n",
    "    if np_type in type_connectivity_table.index:\n",
    "        row_od[\"comment\"] += (\" Connectivity based on Hemibrain v1.2.1 data where each individual of this type \"\n",
    "                              \"has at least %s synapses in a region.\" % connectivity_threshold)\n",
    "    \n",
    "    # connectivity\n",
    "    try:\n",
    "        type_connectivity = type_connectivity_table.loc[np_type]\n",
    "        postsynapses = []\n",
    "        for region in type_connectivity.index:\n",
    "            if type_connectivity['post'][region] >= connectivity_threshold:\n",
    "                postsynapses.append(region)\n",
    "        if postsynapses:\n",
    "            row_od[\"inputs\"] = '|'.join(postsynapses)\n",
    "        presynapses = []\n",
    "        for region in type_connectivity.index:\n",
    "            if type_connectivity['pre'][region] >= connectivity_threshold:\n",
    "                presynapses.append(region)\n",
    "        if presynapses:\n",
    "            row_od[\"outputs\"] = '|'.join(presynapses)\n",
    "    except(KeyError):\n",
    "        pass\n",
    "    \n",
    "    row_od[\"parent\"] = '|'.join(Parents_list)\n",
    "    \n",
    "    #make new row into a DataFrame and add it to template\n",
    "    new_row = pd.DataFrame.from_records([row_od])\n",
    "    template = pd.concat([template, new_row], ignore_index=True, sort=False)\n",
    "\n",
    "    count +=1\n",
    "    \n",
    "    \n",
    "#template.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add rows to specify TYPE for other classes and OPs\n",
    "# this is a workaround for a robot bug - https://github.com/ontodev/robot/issues/1105\n",
    "import re\n",
    "\n",
    "# function to get curies\n",
    "def extract_uris(text):\n",
    "    return re.findall(r'\\b(?:FBbt|GO|PATO|RO):\\d+\\b', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curies = []\n",
    "for column in template.columns:\n",
    "    if column != 'ID':\n",
    "        new_uris = template[column].apply(extract_uris)\n",
    "        # Filter out empty lists\n",
    "        new_uris = new_uris[new_uris.apply(lambda x: len(x) > 0)].explode()\n",
    "        curies.extend(new_uris)\n",
    "        curies = list(set(curies))\n",
    "\n",
    "#curies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a row for each\n",
    "for x in curies:\n",
    "    \n",
    "    # create a dictionary to hold information for this class\n",
    "    row = OrderedDict([])\n",
    "    for c in template.columns:\n",
    "        row[c] = \"\" # setting all as \"\" now to avoid awkward NaNs later\n",
    "    \n",
    "    # populate dictionary\n",
    "    \n",
    "    # annotation axioms\n",
    "    row['ID'] = x\n",
    "    if x.startswith('RO:'):\n",
    "        row['TYPE'] = 'owl:ObjectProperty'\n",
    "    else:\n",
    "        row['TYPE'] = 'owl:Class'\n",
    "    \n",
    "    # turn into dataframe and join to template\n",
    "    row_df = pd.DataFrame.from_dict([row])\n",
    "    template = pd.concat([template, row_df], ignore_index=True)\n",
    "\n",
    "#template.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template.to_csv(\"./template.tsv\", sep = \"\\t\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
