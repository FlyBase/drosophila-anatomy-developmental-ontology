{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Turn CSV into a pandas DataFrame\n",
    "\n",
    "raw_data_table = pd.read_csv('./spreadsheets/L1EM_MB_upstream_neurons.csv', sep=',')\n",
    "\n",
    "# Show first 10 rows of table\n",
    "#raw_data_table[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_IDs = pd.read_csv('./spreadsheets/existing_ID.csv', sep=',')\n",
    "ID_lookup = dict(zip(existing_IDs.Keys,existing_IDs.Values))#FBbt IDs for existing terms\n",
    "#ID_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate FBbt IDs for all new neurons (keys are short names)\n",
    "start = 49008\n",
    "new_term_IDs = list()\n",
    "    \n",
    "for i in raw_data_table.index:\n",
    "    x = start + i\n",
    "    ID = \"FBbt:000\"+str(x)\n",
    "    new_term_IDs.append(ID)\n",
    "\n",
    "new_ID_dict = OrderedDict(zip(raw_data_table.short,new_term_IDs))\n",
    "ID_lookup.update(new_ID_dict)\n",
    "#ID_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save new short name to FBbt mapping as tsv (needed for MB synapsing template)\n",
    "with open('./spreadsheets/FBbt_shortname.tsv', 'w') as f:\n",
    "    for key in new_ID_dict.keys():\n",
    "        f.write(\"%s\\t%s\\n\"%(key,new_ID_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_text = OrderedDict([('FBN' , \"Larval mushroom body one-step feedback neuron\"), \\\n",
    "                          ('FAN' , \"Larval mushroom body feed across neuron\"), \\\n",
    "                          ('FB2N', \"Larval mushroom body two-step feedback neuron\"), \\\n",
    "                          ('FFN', \"Larval mushroom body feedforward neuron\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_maker(short):\n",
    "    group_num = short.split(\"-\")\n",
    "    return (group_text[group_num[0]]).lower() + \" \" + group_num[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Short name to long name dict\n",
    "\n",
    "#MBE neurons (keys are short names)\n",
    "MBE_table = pd.read_csv('./spreadsheets/MBINs_MBONs.csv')\n",
    "longname_dict = OrderedDict(zip(MBE_table.short,MBE_table.Name))\n",
    "longname_dict.update(group_text)\n",
    "for s in raw_data_table.short:\n",
    "    longname_dict[s] = label_maker(s)\n",
    "\n",
    "#longname_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary with key = column header & value = template specification (first row of table).\n",
    "\n",
    "#ID column (optionally add type (default 'class') and class_type (default 'subclass') columns here)\n",
    "\n",
    "template_seed = OrderedDict([('ID' , 'ID')])\n",
    "\n",
    "#label, description, short synonym:\n",
    "\n",
    "template_seed.update([(\"Name\" , \"A rdfs:label\"), (\"Definition\" , \"A IAO:0000115\"),\\\n",
    "                      (\"Xref_def\" , \">A oboInOwl:hasDbXref\"),\\\n",
    "                      (\"created_by\" , \"A dc:contributor\"),\\\n",
    "                      (\"creation_date\", \"A dc:date\")])\n",
    "\n",
    "#short name synonyms\n",
    "template_seed.update([(\"Synonym\" , \"A oboInOwl:hasExactSynonym\"),\\\n",
    "                      (\"syn_ref\" , \">A oboInOwl:hasDbXref\")]) \n",
    "                      \n",
    "\n",
    "# Column for group:\n",
    "template_seed.update([(\"Group\" , \"SC %\")])\n",
    "\n",
    "#Column for NTs\n",
    "template_seed.update([(\"Neurotransmitter\" , \"SC 'capable of' some %\")])\n",
    "\n",
    "#Synapsed_by\n",
    "template_seed.update([(\"Synapsed_by\" , \"SC 'synapsed by' some % SPLIT=|\")])\n",
    "    \n",
    "#Synapsed_to\n",
    "template_seed.update([(\"Synapsed_to\" , \"SC 'synapsed to' some % SPLIT=|\")])\n",
    "    \n",
    "# Create dataFrame for template\n",
    "# from_records takes a list of dicts - one for each row.  We only have one row.\n",
    "\n",
    "template = pd.DataFrame.from_records([template_seed])\n",
    "\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_names = OrderedDict([(\"Glu\" , \"glutamatergic\"), (\"GABA\" , \"GABAergic\"), (\"ACh\" , \"cholinergic\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_lister(names):\n",
    "    L = \"\"\n",
    "    if len(names) < 1:\n",
    "        return False\n",
    "    elif len(names) == 1:\n",
    "        return names[0]\n",
    "    elif len(names) > 1:\n",
    "        L = names[0]\n",
    "        if len(names) > 2:\n",
    "            for i in names[1:-1]:\n",
    "                L = L + \", \" + i\n",
    "        L = L + \" and \" + names[-1]\n",
    "        return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0 #0 = FBN-1\n",
    "\n",
    "for i in raw_data_table.index:\n",
    "\n",
    "    r = raw_data_table.short[count]\n",
    "    row_od = OrderedDict([]) #new template row as an empty ordered dictionary\n",
    "    for c in template.columns: #make columns and blank data for new template row\n",
    "        row_od.update([(c , \"\")])\n",
    "    \n",
    "    #these are the same in each row\n",
    "    row_od[\"Xref_def\"] = \"doi:10.1101/649731\"\n",
    "    row_od[\"syn_ref\"] = \"doi:10.1101/649731\"\n",
    "    row_od[\"created_by\"] = \"http://orcid.org/0000-0002-1373-1705\"\n",
    "    row_od[\"creation_date\"] = \"2020-03-05T12:00:00Z\"\n",
    "\n",
    "    #easy to generate data\n",
    "    row_od[\"ID\"] = new_ID_dict[r]\n",
    "    row_od[\"Synonym\"] = r\n",
    "    row_od[\"Name\"] = label_maker(r)\n",
    "\n",
    "    #Group\n",
    "    row_od[\"Group\"] = ID_lookup[r.split(\"-\")[0]]\n",
    "    \n",
    "    #neurotransmitter\n",
    "    if pd.notna(raw_data_table.NT[count]):\n",
    "        row_od[\"Neurotransmitter\"] = ID_lookup[raw_data_table.NT[count]]\n",
    "    else: row_od[\"Neurotransmitter\"] = \"\"\n",
    "    \n",
    "    #synapsing\n",
    "    if pd.notna(raw_data_table.synapsed_by[count]):\n",
    "        synby_ID_list = [ID_lookup[x] for x in raw_data_table.synapsed_by[count].split(\" \")]\n",
    "        synby_ID_string = \"\"\n",
    "        for i in synby_ID_list:\n",
    "            synby_ID_string = synby_ID_string + i + \" | \"\n",
    "        row_od[\"Synapsed_by\"] = synby_ID_string.rstrip(\" |\")\n",
    "        \n",
    "    if pd.notna(raw_data_table.synapsed_to[count]):\n",
    "        synto_ID_list = [ID_lookup[x] for x in raw_data_table.synapsed_to[count].split(\" \")]\n",
    "        synto_ID_string = \"\"\n",
    "        for i in synto_ID_list:\n",
    "            synto_ID_string = synto_ID_string + i + \" | \"\n",
    "        row_od[\"Synapsed_to\"] = synto_ID_string.rstrip(\" |\")    \n",
    "    \n",
    "    #####STUFF FOR DEFINITION\n",
    "    #group\n",
    "    r_group = raw_data_table.Group[count]\n",
    "    group_def = group_text[r_group]\n",
    "\n",
    "    #neurotransmitter\n",
    "    if pd.notna(raw_data_table.NT[count]):\n",
    "        nt_text = \" and they are %s (Eschbach et al., 2019).\"%(nt_names[raw_data_table.NT[count]])\n",
    "    else: nt_text = \".\"\n",
    "            \n",
    "    #synapsing\n",
    "    if pd.notna(raw_data_table.synapsed_by[count]):\n",
    "        synby_text_list = raw_data_table.synapsed_by[count].split(\" \")\n",
    "        synby_text_list2 = [i + \"s\" if i in [\"MBIN, \"\"MBON\", \"FBN\", \"FAN\", \"FB2N\", \"FFN\"] \\\n",
    "                            else i for i in synby_text_list]\n",
    "        synby_text = \" that receives synaptic input from %s\"\\\n",
    "        %(name_lister(synby_text_list2))\n",
    "    else: synby_text = \"\"\n",
    "\n",
    "    if len(synby_text) > 0:\n",
    "        if pd.notna(raw_data_table.synapsed_to[count]):\n",
    "            synto_text_list = raw_data_table.synapsed_to[count].split(\" \")\n",
    "            synto_text_list2 = [i + \"s\" if i in [\"MBIN, \"\"MBON\", \"FBN\", \"FAN\", \"FB2N\", \"FFN\"] \\\n",
    "                            else i for i in synto_text_list]\n",
    "            synto_text = \" and outputs onto %s (Eschbach et al., 2019).\"\\\n",
    "            %(name_lister(synto_text_list2))\n",
    "        else: synto_text = \" (Eschbach et al., 2019).\"\n",
    "    elif pd.notna(raw_data_table.synapsed_to[count]):\n",
    "        synto_text_list = raw_data_table.synapsed_to[count].split(\" \")\n",
    "        synto_text_list2 = [i + \"s\" if i in [\"MBIN, \"\"MBON\", \"FBN\", \"FAN\", \"FB2N\", \"FFN\"] \\\n",
    "                            else i for i in synto_text_list]\n",
    "        synto_text = \" that outputs onto %s (Eschbach et al., 2019).\"\\\n",
    "        %(name_lister(synto_text_list2))\n",
    "    else: synto_text = \" (Eschbach et al., 2019).\"\n",
    "        \n",
    "    row_od[\"Definition\"] = group_def + synby_text + synto_text + \\\n",
    "    \" There is one bilateral pair of these cells\" + nt_text\n",
    "            \n",
    "    \n",
    "    #make new row into a DataFrame and add it to template\n",
    "    new_row = pd.DataFrame.from_records([row_od])\n",
    "    template = pd.concat([template, new_row], ignore_index=True, sort=False)\n",
    "\n",
    "    count +=1\n",
    "    \n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template.to_csv(\"./template.tsv\", sep = \"\\t\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
