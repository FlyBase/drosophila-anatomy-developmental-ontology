{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from num2words import num2words\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Turn CSV into a pandas DataFrame\n",
    "\n",
    "raw_data_table = pd.read_csv('./spreadsheets/DN-reformatted.csv', sep=',')\n",
    "\n",
    "# Show first 10 rows of table\n",
    "#raw_data_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbrf_table = pd.read_csv('./spreadsheets/fbrf-table.csv', sep=',')\n",
    "lookup = dict(zip(fbrf_table.Keys,fbrf_table.Values))#FBrfs for existing terms\n",
    "#lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice_name_table = pd.read_csv('./spreadsheets/nice-names-table.csv', sep=',')\n",
    "nice_names = dict(zip(nice_name_table.Keys,nice_name_table.Values))#improved names for existing terms from raw_data\n",
    "#nice_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate fbrfs for all descending neurons (keys are short names)\n",
    "start = 47572\n",
    "DN_fbrfs = list()\n",
    "    \n",
    "for i in raw_data_table.index:\n",
    "    x = start + i\n",
    "    ID = \"FBbt:000\"+str(x)\n",
    "    DN_fbrfs.append(ID)\n",
    "\n",
    "DN_dict = OrderedDict(zip(raw_data_table.short,DN_fbrfs))\n",
    "#DN_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save short name to fbrf mapping as tsv\n",
    "with open('fbrf_dnshortname.tsv', 'w') as f:\n",
    "    for key in DN_dict.keys():\n",
    "        f.write(\"%s\\t%s\\n\"%(key,DN_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of fbbts for DN_groups\n",
    "DN_group_names = set(raw_data_table.Group)\n",
    "\n",
    "DN_group_fbbts = list()\n",
    "for i in DN_group_names:\n",
    "    x = lookup[i]\n",
    "    DN_group_fbbts.append(x)\n",
    "\n",
    "#DN_group_names\n",
    "#DN_group_fbbts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of names for processes (neuropils)\n",
    "process_neuropil_names = open('./spreadsheets/neuropils.txt', 'r')\n",
    "process_neuropil_names = process_neuropil_names.read().splitlines()\n",
    "#process_neuropil_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of fbbts for processes (neuropils)\n",
    "processes = list()\n",
    "\n",
    "for i in process_neuropil_names:\n",
    "    x = lookup[i]\n",
    "    processes.append(x)\n",
    "\n",
    "#processes[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of fbbts for pathways (tracts)\n",
    "pathway_tract_names = open('./spreadsheets/tracts.csv', 'r')\n",
    "pathway_tract_names = pathway_tract_names.read().splitlines()\n",
    "#pathway_tract_names[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of fbbts for pathways (tracts)\n",
    "tracts = list()\n",
    "\n",
    "for i in pathway_tract_names:\n",
    "    x = lookup[i]\n",
    "    tracts.append(x)\n",
    "\n",
    "#tracts[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_lister(names):\n",
    "    L = \"\"\n",
    "    if len(names) < 1:\n",
    "        return False\n",
    "    elif len(names) == 1:\n",
    "        return names[0]\n",
    "    elif len(names) > 1:\n",
    "        L = names[0]\n",
    "        if len(names) > 2:\n",
    "            for i in names[1:-1]:\n",
    "                L = L + \", \" + i\n",
    "        L = L + \" and \" + names[-1]\n",
    "        return L\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similar neurons - comment#######################\n",
    "similar_neurons_df = pd.read_csv('./spreadsheets/similar-neurons.tsv', sep='\\t')\n",
    "similar_neurons_df = similar_neurons_df.fillna(\"\") #must do this first - won't replace 'nan'\n",
    "similar_neurons_df = similar_neurons_df.applymap(str) #convert everything to a string\n",
    "\n",
    "sim_comment_od = OrderedDict([])\n",
    "\n",
    "for dn in raw_data_table.short:\n",
    "    if dn in list(similar_neurons_df.Name):#can't use \"in\" with pd series\n",
    "        sim_rows = similar_neurons_df[similar_neurons_df.Name == dn]#table with row for each similar neuron for one dn\n",
    "        sim_name_list = list()\n",
    "        #build up a statement for each row and add to list\n",
    "        for r in sim_rows.index:\n",
    "            sim_text = \"\"\n",
    "            sim_text = sim_text + sim_rows.sim_name[r]\n",
    "            if len(sim_rows.fbbt[r]) > 0:\n",
    "                sim_text = sim_text + \" (\" + sim_rows.fbbt[r] + \")\"\n",
    "            sim_text = sim_text + \", described by \" + sim_rows.Citation[r]\n",
    "            if len(sim_rows.fbrf[r]) > 0:\n",
    "                sim_text = sim_text + \" (\" + sim_rows.fbrf[r] + \")\"\n",
    "            sim_name_list.append(sim_text)\n",
    "        #put together list items with ',' and 'and' in a sentence\n",
    "        sim_comment_od[dn] = \"Namiki et al., 2018 (FBrf0239335), identify this as being morphologically similar to \"\\\n",
    "        + name_lister(sim_name_list) + \".\"\n",
    "        sim_name_list.clear\n",
    "\n",
    "#similar_neurons_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"may be equivalent to\" field\n",
    "\n",
    "sim_eqto_od = OrderedDict([])\n",
    "\n",
    "for dn in raw_data_table.short:\n",
    "    if dn in list(similar_neurons_df.Name):\n",
    "        sim_rows = similar_neurons_df[similar_neurons_df.Name == dn]#table with row for each similar neuron for one dn\n",
    "        sim_fbbt = list()\n",
    "        for r in sim_rows.index:#make list of fbbts for one dn\n",
    "            if len(sim_rows.fbbt[r]) > 0:\n",
    "                eq_fbbt = \"http://purl.obolibrary.org/obo/\" + sim_rows.fbbt[r].replace(\":\",\"_\")\n",
    "                sim_fbbt.append(eq_fbbt)\n",
    "            if len(sim_fbbt) > 0:\n",
    "                sim_eqto_od[dn] = sim_fbbt\n",
    "        sim_fbbt.clear\n",
    "\n",
    "max_eqto = 0        \n",
    "for i in sim_eqto_od:\n",
    "    if len(sim_eqto_od[i]) > max_eqto:\n",
    "        max_eqto = len(sim_eqto_od[i])\n",
    "        \n",
    "#max_eqto\n",
    "#sim_eqto_od[\"DNg34\"]\n",
    "#sim_eqto_od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary with key - column header & value = template specification (first row of table).\n",
    "# Make first two columns\n",
    "\n",
    "template_seed = OrderedDict([ ('ID' , 'ID'), ('CLASS_TYPE' , 'CLASS_TYPE'),\\\n",
    "                             ('RDF_Type' , 'TYPE' )])\n",
    "\n",
    "#label, description, short synonym:\n",
    "\n",
    "template_seed.update([(\"Name\" , \"A rdfs:label\"), (\"Definition\" , \"A IAO:0000115\"),\\\n",
    "                      (\"Xref_def\" , \">A oboInOwl:hasDbXref\"), (\"Comment\" , \"A rdfs:comment\"),\\\n",
    "                      (\"created_by\" , \"A dc:contributor\"),\\\n",
    "                      (\"creation_date\", \"A dc:date\")])\n",
    "\n",
    "#short name synonyms\n",
    "template_seed.update([(\"Synonym1\" , \"A oboInOwl:hasExactSynonym\"),\\\n",
    "                      (\"syn_type\" , \">A oboInOwl:HasSynonymType\"),\\\n",
    "                      (\"Synonym2\" , \"A oboInOwl:hasExactSynonym\"),\\\n",
    "                      (\"syn_ref\" , \">A oboInOwl:hasDbXref\")]) \n",
    "\n",
    "#may be equivalent to annotation\n",
    "#AI specifies an IRI\n",
    "for i in range(max_eqto):\n",
    "    template_seed.update([(\"eq_to\" + str(i+1), \"AI IAO:0006011\"),\\\n",
    "                          (\"eq_to_ref\" + str(i+1), \">A oboInOwl:hasDbXref\")])\n",
    "                      \n",
    "\n",
    "# Columns for DN group:\n",
    "for n in DN_group_fbbts:\n",
    "    template_seed.update([(n , \"C %\")])\n",
    "\n",
    "# Columns for processes:\n",
    "for n in processes:\n",
    "    template_seed.update([(n , \"C 'has synaptic terminal in' some %\")])\n",
    "\n",
    "# Columns for tract:\n",
    "for n in tracts:\n",
    "    template_seed.update([(n , \"C 'fasciculates with' some %\")])\n",
    "\n",
    "\n",
    "# Create dataFrame for template\n",
    "# from_records takes a list of dicts - one for each row.  We only have one row.\n",
    "\n",
    "template = pd.DataFrame.from_records([template_seed])\n",
    "\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_text_generator(group):\n",
    "    if group == 'DNa':\n",
    "        return \"Descending neuron belonging to the DNa group, having a cell body on the anterior dorsal surface of the brain.\"\n",
    "    elif group == 'DNb':\n",
    "        return \"Descending neuron belonging to the DNb group, having a cell body on the anterior ventral surface of the brain.\"\n",
    "    elif group == 'DNc':\n",
    "        return \"Descending neuron belonging to the DNc group, having a cell body in the pars intercerebralis.\"\n",
    "    elif group == 'DNd':\n",
    "        return \"Descending neuron belonging to the DNd group, having a cell body just lateral to the antennal lobe, on the anterior surface of the brain.\"\n",
    "    elif group == 'DNg':\n",
    "        return \"Descending neuron belonging to the DNg group, having a cell body in the cell body rind around the gnathal ganglion.\"\n",
    "    elif group == 'DNp':\n",
    "        return \"Descending neuron belonging to the DNp group, having a cell body on the posterior surface of the brain.\"\n",
    "    elif group == 'DNx':\n",
    "        return \"Descending neuron belonging to the DNx group, having a cell body outside of the brain.\"\n",
    "    else: print(\"Please enter a valid group\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_text_generator(cells):\n",
    "    if cells > 1:\n",
    "        return \" There is a cluster of up to %s of these cells in each hemisphere.\"%(num2words(cells))\n",
    "    elif cells == 1:\n",
    "        return \" There is one of these cells per hemisphere.\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def side_text_generator(cross,side):\n",
    "    c_s_dict = {\"N\" : \" This neuron does not cross the midline\", \"Y\" : \" This neuron crosses the midline\",\\\n",
    "                \"I\" : \" and descends on the ipsilateral side of the cervical connective.\",\\\n",
    "                \"C\" : \" and descends on the contralateral side of the cervical connective.\"}\n",
    "    return c_s_dict[cross] + c_s_dict[side]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_maker(short):\n",
    "    letter_regions = {\"a\" : \"of the anterior dorsal brain\", \"b\" : \"of the anterior ventral brain\",\\\n",
    "                      \"c\" : \"of the pars intercerebralis\", \"d\" : \"of the anterior brain\",\\\n",
    "                      \"g\" : \"of the gnathal ganglion\", \"p\" : \"of the posterior brain\",\\\n",
    "                      \"x\" : \"outside of the brain\"}\n",
    "    region = letter_regions[short[2]]\n",
    "    return \"descending neuron %s %s\"%(region,short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0 #0 = DNa01\n",
    "\n",
    "for i in raw_data_table.index:\n",
    "\n",
    "    r = raw_data_table.short[count]\n",
    "    row_od = OrderedDict([]) #new template row as an empty ordered dictionary\n",
    "    for c in template.columns: #make columns and blank data for new template row\n",
    "        row_od.update([(c , \"\")])\n",
    "    \n",
    "    #these are the same in each row\n",
    "    row_od[\"CLASS_TYPE\"] = \"subclass\"\n",
    "    row_od[\"RDF_Type\"] = \"owl:Class\"\n",
    "    row_od[\"Xref_def\"] = \"FlyBase:FBrf0239335\"\n",
    "    row_od[\"syn_type\"] = \"http://purl.obolibrary.org/obo/fbbt#VFB_SYMBOL\"\n",
    "    row_od[\"syn_ref\"] = \"FlyBase:FBrf0239335\"\n",
    "    row_od[\"created_by\"] = \"CP\"\n",
    "    row_od[\"creation_date\"] = \"2018-09-20T12:00:00Z\"\n",
    "\n",
    "    #easy to generate data\n",
    "    row_od[\"ID\"] = DN_dict[r]\n",
    "    row_od[\"Synonym1\"] = r\n",
    "    row_od[\"Synonym2\"] = r\n",
    "    row_od[\"Name\"] = label_maker(r)\n",
    "    if r in sim_comment_od:\n",
    "        row_od[\"Comment\"] = sim_comment_od[r]\n",
    "\n",
    "    #is_a relationship\n",
    "    is_a = lookup[r[0:3]]\n",
    "    row_od[is_a] = is_a\n",
    "    \n",
    "    #may be equivalent to\n",
    "    if r in sim_eqto_od:\n",
    "        count_eq = 0\n",
    "        for i in sim_eqto_od[r]:\n",
    "            count_eq += 1\n",
    "            row_od[\"eq_to\" + str(count_eq)] = i\n",
    "            row_od[\"eq_to_ref\" + str(count_eq)] = \"FlyBase:FBrf0239335\"    \n",
    "    \n",
    "    #FOR SYNAPSING AND FASCICULATION\n",
    "    #get column names where value > 0\n",
    "    names = raw_data_table[:count].columns[(raw_data_table > 0).iloc[count]]\n",
    "    #convert these to FBrfs\n",
    "    FBrfs = list()\n",
    "    for n in names:\n",
    "        if n in lookup:\n",
    "            FBrfs.append(lookup[n])\n",
    "        else: continue\n",
    "    #make these into columns in row_od\n",
    "    for f in FBrfs:\n",
    "        row_od[f] = f\n",
    "    \n",
    "    #STUFF FOR DEFINITION\n",
    "    #DN group\n",
    "    r_group = raw_data_table.Group[count]\n",
    "    group_text = group_text_generator(r_group)\n",
    "    #number_cells\n",
    "    num_cells = raw_data_table.max_cells[count]\n",
    "    number_cells_text = cell_text_generator(num_cells)\n",
    "    #crossing and descending side\n",
    "    cross = raw_data_table.crossing_midline[count]\n",
    "    side = raw_data_table.Descending_side[count]\n",
    "    side_text = side_text_generator(cross,side)\n",
    "    \n",
    "    #using x > 0 names generated for relationships\n",
    "    synapsing_names = list()\n",
    "    for n in names:\n",
    "        if (n in nice_names) and (n in process_neuropil_names):\n",
    "            synapsing_names.append(nice_names[n])\n",
    "        else: continue\n",
    "    \n",
    "    synapses_in = name_lister(synapsing_names)\n",
    "    if synapses_in != False:\n",
    "        synapsing_text = \" It has neurites in the \" + synapses_in + \".\"\n",
    "    else: synapsing_text = \"\"\n",
    "    \n",
    "    tract_names = list()\n",
    "    for n in names:\n",
    "        if (n in nice_names) and (n in pathway_tract_names):\n",
    "            tract_names.append(nice_names[n])\n",
    "        else: continue\n",
    "            \n",
    "    in_tracts = name_lister(tract_names)\n",
    "    if in_tracts != False:\n",
    "        tract_text = \" It fasciculates with the \" + in_tracts + \" in the thoracico-abdominal ganglion.\"\n",
    "    else: tract_text = \"\"\n",
    "\n",
    "            \n",
    "    row_od[\"Definition\"] = group_text + side_text + synapsing_text + tract_text + number_cells_text\n",
    "            \n",
    "    \n",
    "    #make new row into a DataFrame and add it to template\n",
    "    new_row = pd.DataFrame.from_records([row_od])\n",
    "    template = pd.concat([template, new_row], ignore_index=True, sort=False)\n",
    "\n",
    "    count +=1\n",
    "    \n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template.to_csv(\"./template.tsv\", sep = \"\\t\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
